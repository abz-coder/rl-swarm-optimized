import logging  
import os
import sys
import time
from collections import defaultdict
from pathlib import Path

from genrl.blockchain import SwarmCoordinator
from genrl.communication import Communication
from genrl.communication.hivemind.hivemind_backend import HivemindBackend
from genrl.data import DataManager
from genrl.game import BaseGameManager
from genrl.game.game_manager import DefaultGameManagerMixin
from genrl.logging_utils.global_defs import get_logger
from genrl.logging_utils.system_utils import get_system_info
from genrl.rewards import RewardManager
from genrl.roles import RoleManager
from genrl.state import GameState
from genrl.trainer import TrainerModule
from huggingface_hub import login, whoami

from rgym_exp.src.utils.name_utils import get_name_from_peer_id


class SwarmGameManager(BaseGameManager, DefaultGameManagerMixin):
    """GameManager that orchestrates a game using a SwarmCoordinator."""

    def __init__(
        self,
        coordinator: SwarmCoordinator,
        max_stage: int,
        max_round: int,
        game_state: GameState,
        reward_manager: RewardManager,
        trainer: TrainerModule,
        data_manager: DataManager,
        communication: Communication,
        role_manager: RoleManager | None = None,
        run_mode: str = "train",
        log_dir: str = "logs",
        hf_token: str | None = None,
        hf_push_frequency: int = 20,
        submit_frequency: int = 3,
        **kwargs,
    ):

        super().__init__(
            max_stage=max_stage,
            max_round=max_round,
            game_state=game_state,
            reward_manager=reward_manager,
            trainer=trainer,
            data_manager=data_manager,
            communication=communication,
            role_manager=role_manager,
            run_mode=run_mode,
        )

        assert isinstance(self.communication, HivemindBackend)
        self.train_timeout = 60 * 60 * 24 * 31  # 1 month

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ peer ID Ğ¾Ñ‚ HivemindBackend
        self.peer_id = self.communication.get_id()
        self.state.peer_id = self.peer_id
        self.animal_name = get_name_from_peer_id(self.peer_id, True)
        
        # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ peer ID
        get_logger().info(f"ğŸ†” Peer ID generated: {self.peer_id}")
        get_logger().info(f"ğŸ¾ Animal name: {self.animal_name}")

        # Logging Setup
        format_msg = f"[{self.animal_name}] %(asctime)s %(levelname)s: %(message)s"
        logging.basicConfig(level=logging.INFO, format=format_msg)
        formatter = logging.Formatter(format_msg)
        file_handler = logging.FileHandler(
            os.path.join(log_dir, f"training_{self.animal_name}.log")
        )
        file_handler.setFormatter(formatter)
        _LOG = get_logger()
        _LOG.addHandler(file_handler)

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ coordinator Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ±Ğ»Ğ¾ĞºÑ‡ĞµĞ¹Ğ½Ğ¾Ğ¼
        self.coordinator = coordinator
        
        # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ±Ğ»Ğ¾ĞºÑ‡ĞµĞ¹Ğ½ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğµ
        get_logger().info("ğŸ”— Initializing blockchain coordinator connection...")
        get_logger().info(f"ğŸ“¡ Blockchain coordinator type: {type(coordinator).__name__}")
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ bootnodes Ğ¸Ğ· Ğ±Ğ»Ğ¾ĞºÑ‡ĞµĞ¹Ğ½Ğ°
        try:
            get_logger().info("ğŸ“¡ Getting bootnodes from blockchain...")
            bootnodes = self.coordinator.get_bootnodes()
            get_logger().info(f"âœ… Successfully retrieved {len(bootnodes)} bootnodes from blockchain:")
            for i, bootnode in enumerate(bootnodes):
                get_logger().info(f"  ğŸ“ Bootnode {i+1}: {bootnode}")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ bootnodes Ğ½Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ
            if bootnodes:
                get_logger().info("âœ… Blockchain bootnodes available - system will connect to main network")
            else:
                get_logger().warning("âš ï¸  No bootnodes returned from blockchain - check network connection")
                
        except Exception as e:
            get_logger().error(f"âŒ Failed to get bootnodes from blockchain: {e}")
            get_logger().warning("âš ï¸  This may indicate blockchain connection issues")

        # Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ peer ID Ğ² Ğ±Ğ»Ğ¾ĞºÑ‡ĞµĞ¹Ğ½Ğµ
        get_logger().info("ğŸ” Registering peer ID in blockchain...")
        try:
            self.coordinator.register_peer(self.peer_id)
            get_logger().info(f"âœ… Successfully registered peer ID [{self.peer_id}] in blockchain")
            get_logger().info("ğŸ”— Peer is now linked to blockchain identity")
        except Exception as e:
            get_logger().error(f"âŒ Failed to register peer ID in blockchain: {e}")
            get_logger().warning("âš ï¸  This may affect on-chain participation")

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€Ğ°ÑƒĞ½Ğ´ Ğ¸Ğ· Ğ±Ğ»Ğ¾ĞºÑ‡ĞµĞ¹Ğ½Ğ°
        try:
            get_logger().info("ğŸ“Š Getting current round from blockchain...")
            round, stage = self.coordinator.get_round_and_stage()
            get_logger().info(f"âœ… Retrieved current round: {round}, stage: {stage}")
            
            self.state.round = round
            self.communication.step_ = self.state.round
            
            get_logger().info(f"ğŸ¯ Synchronized with blockchain - starting from round {round}")
            
        except Exception as e:
            get_logger().error(f"âŒ Failed to get round/stage from blockchain: {e}")
            get_logger().warning("âš ï¸  Using default round/stage values")

        self.submit_frequency = submit_frequency

        get_logger().info(f"ğŸ± Hello ğŸˆ [{get_name_from_peer_id(self.peer_id)}] ğŸ¦® [{self.peer_id}]!")
        get_logger().info(f"ğŸ”— Bootnodes from config: {kwargs.get('bootnodes', [])}")

        # Safely get the model name first, then use it.
        model_name = "UnknownModel"
        
        # Check if we are in vLLM mode
        if hasattr(self.trainer, "use_vllm") and self.trainer.use_vllm:
            # In vLLM mode, use the name we saved in the trainer
            model_name = getattr(self.trainer, "model_name", "vLLM_Model")
            get_logger().info("ğŸš€ Running in vLLM mode - fast inference enabled")
        else:
            # In standard training mode, safely access the config attribute
            config_obj = getattr(getattr(self.trainer, "model", None), "config", None)
            if config_obj:
                model_name = getattr(config_obj, "_name_or_path", "UnknownModel")
            get_logger().info("ğŸ‹ï¸ Running in standard training mode")
        
        get_logger().info(f"ğŸ¤– Using Model: {model_name}")

        # Enable push to HF if token was provided
        self.hf_token = hf_token
        if self.hf_token not in [None, "None"]:
            get_logger().info("ğŸ¤— Setting up Hugging Face integration...")
            # This block should only run if we can actually push, which means we're in training mode.
            if not (hasattr(self.trainer, "use_vllm") and self.trainer.use_vllm):
                try:
                    username = whoami(token=self.hf_token)["name"]
                    model_name_suffix = model_name.split("/")[-1]
                    hub_model_id = f"{username}/{model_name_suffix}-Gensyn-Swarm-{self.animal_name}"
                    
                    self.trainer.args.hub_model_id = hub_model_id
                    self.trainer.args.push_to_hub = True
                    self.trainer.args.hub_token = self.hf_token
                    self.hf_push_frequency = hf_push_frequency
                    get_logger().info("Logging into Hugging Face Hub...")
                    login(self.hf_token)
                    get_logger().info(f"âœ… Hugging Face setup complete - model will push to {self.trainer.args.hub_model_id}")
                except Exception as e:
                    get_logger().warning(f"Could not set up Hugging Face push. Error: {e}")
            else:
                get_logger().info("Hugging Face push is disabled in vLLM mode.")
        else:
            get_logger().info("ğŸ“¤ Hugging Face push disabled - no token provided")
        
        # Ğ ĞµĞ·ÑĞ¼Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
        get_logger().info("ğŸ“‹ Connection Summary:")
        get_logger().info("  ğŸ” Peer ID: Generated and registered âœ…")
        get_logger().info("  ğŸŒ DHT Network: Initialized âœ…")
        get_logger().info("  â›“ï¸  Blockchain: Connected âœ…")
        get_logger().info("  ğŸ“¡ Bootnodes: Retrieved from blockchain âœ…")
        get_logger().info("  ğŸ¯ Ready to participate in main swarm network!")

        with open(os.path.join(log_dir, f"system_info.txt"), "w") as f:
            f.write(get_system_info())

    def _get_total_rewards_by_agent(self):
        rewards_by_agent = defaultdict(int)
        for stage in range(self.state.stage):
            rewards = self.rewards[stage]
            for agent_id, agent_rewards in rewards.items():
                for batch_id, batch_rewards in agent_rewards.items():
                    tot = 0
                    for generation_rewards in batch_rewards:
                        tot += sum(generation_rewards)
                    rewards_by_agent[agent_id] += tot

        return rewards_by_agent

    def _hook_after_rewards_updated(self):
        if self.state.round % self.submit_frequency == 0:
            rewards_by_agent = self._get_total_rewards_by_agent()
            my_rewards = rewards_by_agent[self.peer_id]
            my_rewards = (my_rewards + 1) * (my_rewards > 0) + my_rewards * (my_rewards <= 0)
            self.coordinator.submit_reward(self.state.round, 0, int(my_rewards), self.peer_id)

            max_agent, max_rewards = max(rewards_by_agent.items(), key=lambda x: x[1])
            self.coordinator.submit_winners(self.state.round, [max_agent], self.peer_id)

    def _hook_after_round_advanced(self):
        self._save_to_hf()
        self.agent_block()

    def _hook_after_game(self):
        self._save_to_hf()

    def _save_to_hf(self):
        if self.hf_token not in [None, "None"] and self.state.round % self.hf_push_frequency == 0:
            get_logger().info(f"pushing model to huggingface")
            try:
                repo_id = self.trainer.args.hub_model_id
                if repo_id is None:
                    repo_id = Path(self.trainer.args.output_dir).name

                self.trainer.model.push_to_hub(
                    repo_id=repo_id,
                    token=self.hf_token,
                    commit_message=f"rl-swarm: round {self.state.round}, agent {self.animal_name}",
                    tags=[
                        "rl-swarm",
                        "genrl-swarm",
                        "grpo",
                        "gensyn",
                        f"I am {self.animal_name}",
                    ],
                )
            except Exception:
                get_logger().exception(
                    "Failed to push model to the Hugging Face Hub. When you conclude training please try manually pushing it yourself using the instructions here: https://huggingface.co/docs/hub/en/models-uploading",
                    stack_info=True,
                )

    def agent_block(self, check_interval=5.0, log_timeout=10.0, max_check_interval=60.0 * 15):
        start_time = time.monotonic()
        fetch_log_time = start_time
        check_backoff = check_interval
        while time.monotonic() - start_time < self.train_timeout:
            curr_time = time.monotonic()
            _ = self.communication.dht.get_visible_maddrs(latest=True)

            try:
                round_num, stage = self.coordinator.get_round_and_stage()
            except Exception as e:
                if curr_time - fetch_log_time > log_timeout:
                    get_logger().debug(
                        f"Could not fetch round and stage: {e}. Next check in {check_interval}s."
                    )
                    fetch_log_time = curr_time

                time.sleep(check_interval)
                continue

            if round_num >= self.state.round:
                get_logger().info(f"ğŸ Joining round: {round_num}")
                check_backoff = check_interval
                self.state.round = round_num
                return
            else:
                get_logger().info(f"Already finished round: {round_num}. Next check in {check_backoff}s.")
                time.sleep(check_backoff)
                check_backoff = min(check_backoff * 2, max_check_interval)

            if round_num == self.max_round - 1:
                return

        get_logger().info("Training timed out!")
